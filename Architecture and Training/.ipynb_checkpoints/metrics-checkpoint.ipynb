{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1423de-1c59-4ce7-b189-f897495656c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "\n",
    "import lpips\n",
    "import torch\n",
    "\n",
    "# Load LPIPS model (AlexNet by default)\n",
    "lpips_model = lpips.LPIPS(net='alex')  # or 'vgg', 'squeeze'\n",
    "lpips_model = lpips_model.eval().cuda()  # if you have GPU\n",
    "\n",
    "# Load InceptionV3 for FID\n",
    "inception_model = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))\n",
    "\n",
    "def preprocess_for_fid(img_batch):\n",
    "    img_batch = tf.image.resize(img_batch, (299, 299))\n",
    "    img_batch = preprocess_input(img_batch * 255.0)\n",
    "    return img_batch\n",
    "\n",
    "def get_activations(images):\n",
    "    images = preprocess_for_fid(images)\n",
    "    activations = inception_model.predict(images, verbose=0)\n",
    "    return activations\n",
    "\n",
    "def calculate_fid(act1, act2):\n",
    "    mu1, sigma1 = act1.mean(axis=0), np.cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), np.cov(act2, rowvar=False)\n",
    "    ssdiff = np.sum((mu1 - mu2)**2.0)\n",
    "    covmean = sqrtm(sigma1 @ sigma2)\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    return ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "\n",
    "def compute_psnr_ssim(generator, val_dataset):\n",
    "    psnr_scores, ssim_scores = [], []\n",
    "    for lr_img, hr_img in val_dataset:\n",
    "        sr_img = generator(lr_img, training=False)\n",
    "        sr_img = tf.clip_by_value(sr_img, 0.0, 1.0)\n",
    "        hr_img = tf.clip_by_value(hr_img, 0.0, 1.0)\n",
    "        psnr = tf.image.psnr(hr_img, sr_img, max_val=1.0).numpy()\n",
    "        ssim = tf.image.ssim(hr_img, sr_img, max_val=1.0).numpy()\n",
    "        psnr_scores.extend(psnr.flatten())\n",
    "        ssim_scores.extend(ssim.flatten())\n",
    "    return np.mean(psnr_scores), np.mean(ssim_scores)\n",
    "\n",
    "def compute_fid(generator, val_dataset, max_batches=50):\n",
    "    real_images, fake_images = [], []\n",
    "    for i, (lr, hr) in enumerate(val_dataset):\n",
    "        if i >= max_batches:\n",
    "            break\n",
    "        sr = generator(lr, training=False)\n",
    "        sr = tf.clip_by_value(sr, 0.0, 1.0)\n",
    "        hr = tf.clip_by_value(hr, 0.0, 1.0)\n",
    "        real_images.append(hr[0])\n",
    "        fake_images.append(sr[0])\n",
    "    real_images = tf.stack(real_images)\n",
    "    fake_images = tf.stack(fake_images)\n",
    "    act1 = get_activations(real_images)\n",
    "    act2 = get_activations(fake_images)\n",
    "    return calculate_fid(act1, act2)\n",
    "\n",
    "def compute_lpips(generator, val_dataset, max_batches=50):\n",
    "    lpips_scores = []\n",
    "    for i, (lr, hr) in enumerate(val_dataset):\n",
    "        if i >= max_batches:\n",
    "            break\n",
    "\n",
    "        sr = generator(lr, training=False)\n",
    "        sr = tf.clip_by_value(sr, 0.0, 1.0)\n",
    "        hr = tf.clip_by_value(hr, 0.0, 1.0)\n",
    "\n",
    "        # Convert TensorFlow tensors to NumPy arrays, then to PyTorch tensors\n",
    "        sr_np = sr[0].numpy().transpose(2, 0, 1)  # [C, H, W]\n",
    "        hr_np = hr[0].numpy().transpose(2, 0, 1)\n",
    "\n",
    "        sr_tensor = torch.from_numpy(sr_np).unsqueeze(0).float().cuda()\n",
    "        hr_tensor = torch.from_numpy(hr_np).unsqueeze(0).float().cuda()\n",
    "\n",
    "        # Normalize to [-1, 1] for LPIPS\n",
    "        sr_tensor = sr_tensor * 2 - 1\n",
    "        hr_tensor = hr_tensor * 2 - 1\n",
    "\n",
    "        lpips_score = lpips_model(sr_tensor, hr_tensor).item()\n",
    "        lpips_scores.append(lpips_score)\n",
    "\n",
    "    avg_lpips = sum(lpips_scores) / len(lpips_scores)\n",
    "    print(f\"Average LPIPS: {avg_lpips:.4f}\")\n",
    "    return avg_lpips\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your models here\n",
    "    from srgan import Generator  # example import\n",
    "    from srwgan import GeneratorSRWGAN  # if custom object needed\n",
    "\n",
    "    wgan = load_model(\"checkpoints/wgan_generator_epoch_200.h5\")\n",
    "    srgan = Generator(10)\n",
    "    srgan.load_weights(\"checkpoints/srgan_generator_epoch_200.h5\")\n",
    "    srwgan = load_model(\"checkpoints/srwgan_generator_epoch_200.h5\", custom_objects={'GeneratorSRWGAN': GeneratorSRWGAN})\n",
    "\n",
    "    from dataset import val_dataset  # Ensure this exists and is preprocessed\n",
    "    val_batches = list(val_dataset)\n",
    "    for name, model in zip([\"WGAN\", \"SRGAN\", \"SRWGAN\"], [wgan, srgan, srwgan]):\n",
    "        psnr, ssim = compute_psnr_ssim(model, val_batches)\n",
    "        fid = compute_fid(model, val_batches)\n",
    "        lpips = compute_lpips(model, val_batches)\n",
    "        print(f\"{name}: PSNR={psnr:.4f}, SSIM={ssim:.4f}, FID={fid:.4f}, LPIPS={lpips:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
